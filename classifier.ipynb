{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Used to load class-to-label mappings from a JSON file.\n",
    "import json\n",
    "import torch\n",
    "# Used to handle image loading.\n",
    "from PIL import Image\n",
    "# Base class for custom PyTorch datasets, allowing integration with DataLoader.\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "epochs = 100\n",
    "# Specifies the batch size of 64 images, meaning each iteration of training will process 64 images at once.\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "imagenet_data_dir_train = \"./ImageNet-Mini/train\"\n",
    "imagenet_data_dir_test = \"./ImageNet-Mini/test\"\n",
    "validation_split = 0.2\n",
    "shuffle = True  # DataLoader.shuffle\n",
    "# Sets the number of CPU cores for loading data, speeding up data loading by using multiple parallel workers.\n",
    "num_workers = 4  # DataLoader.num_workers\n",
    "# Indicates that there are 1,000 classes in MiniImageNet, matching the number of output classes expected for the classification task.\n",
    "n_classes = 1000\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')  # Use MPS for Apple Silicon\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')  # Use CUDA for NVIDIA GPUs\n",
    "else:\n",
    "    device = torch.device('cpu')  # Fallback to CPU\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Dataset Class, instatiate with our data\n",
    "class MiniImageNetDataset(Dataset):\n",
    "    def __init__(self, data_path: str, transform: transforms = None):\n",
    "        self.data_path = data_path\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.class_mapping = {}\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "        # imagenet_class_index.json - This file contains mappings from ImageNet class IDs to human-readable names.\n",
    "        class_index_path = os.path.join(data_path, 'imagenet_class_index.json')\n",
    "        with open(class_index_path, 'r') as f:\n",
    "            # Loads the JSON file and formats it into a dictionary class_id_to_name, where each class name points \n",
    "            # to a tuple of the numeric class ID and the class description.\n",
    "            class_id_to_name = json.load(f)\n",
    "        class_id_to_name = {v[0]: [k, v[1]]for k, v in class_id_to_name.items()}\n",
    "\n",
    "        # Build the Dataset\n",
    "        image_dir = os.path.join(data_path, 'images')\n",
    "        for class_name in sorted(os.listdir(image_dir)):\n",
    "            class_path = os.path.join(image_dir, class_name)\n",
    "            for image_name in sorted(os.listdir(class_path)):\n",
    "                image_path = os.path.join(class_path, image_name)\n",
    "                self.image_paths.append(image_path)\n",
    "                \n",
    "                class_map = class_id_to_name[class_name]\n",
    "                self.class_mapping[int(class_map[0])] = class_map[1]\n",
    "                self.labels.append(int(class_map[0]))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = torch.tensor(self.labels[idx])\n",
    "        \n",
    "        # Load image as PIL format\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing Configs\n",
    "# Chains together a list of transformations to be applied to each image in sequence.\n",
    "transform = transforms.Compose([\n",
    "    # The first convolutional layer filters the 224 × 224 × 3 input image with 96 kernels of size 11 × 11 × 3 with a stride of 4 pixels\n",
    "    # Resize inputs to 224 × 224\n",
    "    transforms.Resize((224, 224)),\n",
    "    # Converts images to tensors -  Converts images from a range of [0,255][0,255] integers to a range of [0,1][0,1] floats and changes them from PIL images to PyTorch tensors.\n",
    "    transforms.ToTensor(),\n",
    "    # Normalize for ImageNet models -  Normalizes the tensor to have a mean and standard deviation corresponding to ImageNet, with each color channel normalized independently.\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MiniImageNetDataset(data_path='./ImageNet-Mini', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_split = int(len(dataset) * 0.2)\n",
    "train_split = len(dataset) - val_split\n",
    "train_set, val_set = random_split(dataset, [train_split, val_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.2489,  2.2489,  2.2489,  ..., -1.5014, -1.5185, -1.6042],\n",
       "         [ 2.2489,  2.2489,  2.2489,  ..., -1.5185, -1.6042, -1.6213],\n",
       "         [ 2.2489,  2.2489,  2.2489,  ..., -1.6384, -1.6213, -1.5699],\n",
       "         ...,\n",
       "         [ 2.1975,  2.2147,  2.2147,  ..., -0.0801, -0.1486, -0.3369],\n",
       "         [ 2.2318,  2.2318,  2.2318,  ..., -0.1143, -0.1486, -0.3712],\n",
       "         [ 2.2147,  2.2318,  2.2318,  ..., -0.1657, -0.2856, -0.5767]],\n",
       "\n",
       "        [[ 2.4286,  2.4286,  2.4286,  ..., -1.4580, -1.4580, -1.5630],\n",
       "         [ 2.4286,  2.4286,  2.4286,  ..., -1.4230, -1.4580, -1.5455],\n",
       "         [ 2.4286,  2.4286,  2.4286,  ..., -1.5105, -1.5105, -1.5105],\n",
       "         ...,\n",
       "         [ 2.4111,  2.4111,  2.4111,  ..., -0.8803, -0.9153, -1.0728],\n",
       "         [ 2.4111,  2.4111,  2.4111,  ..., -0.9153, -0.9853, -1.1253],\n",
       "         [ 2.4286,  2.4286,  2.4111,  ..., -0.8803, -1.0028, -1.3354]],\n",
       "\n",
       "        [[ 2.6400,  2.6400,  2.6400,  ..., -1.3164, -1.2990, -1.3513],\n",
       "         [ 2.6400,  2.6400,  2.6400,  ..., -1.2641, -1.3687, -1.3339],\n",
       "         [ 2.6400,  2.6400,  2.6400,  ..., -1.2816, -1.3687, -1.3861],\n",
       "         ...,\n",
       "         [ 2.4308,  2.5180,  2.5529,  ..., -1.4384, -1.4733, -1.4036],\n",
       "         [ 2.5529,  2.6051,  2.5877,  ..., -1.4384, -1.4210, -1.5779],\n",
       "         [ 2.4308,  2.5529,  2.5703,  ..., -1.6127, -1.5256, -1.5081]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(910)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNetClassifier(nn.Module):\n",
    "    # 1000 classes in ImageNet\n",
    "    def __init__(self, n_classes: int=1000):\n",
    "        super(AlexNetClassifier, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.model_features = nn.Sequential(\n",
    "            self.conv1, nn.ReLU(True), nn.MaxPool2d((3, 3), (2, 2)),\n",
    "            self.conv2, nn.ReLU(True), nn.MaxPool2d((3, 3), (2, 2)),\n",
    "            self.conv3, nn.ReLU(True),\n",
    "            self.conv4, nn.ReLU(True),\n",
    "            self.conv5, nn.ReLU(True), nn.MaxPool2d((3, 3), (2, 2)),\n",
    "        )\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "\n",
    "        # The fully-connected layers have 4096 neurons each as stated in the paper.\n",
    "        self.n_neurons = 4096\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 6 * 6, self.n_neurons),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.n_neurons, self.n_neurons),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(self.n_neurons, self.n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.model_features(x)\n",
    "        out = self.avg_pool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        return self.classifier(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNetClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for imgs, targets in loader:\n",
    "            imgs, targets = imgs.to(device), targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 6.9353\n",
      "Epoch [2/100], Loss: 6.9019\n",
      "Epoch [3/100], Loss: 6.8989\n",
      "Epoch [4/100], Loss: 6.9067\n",
      "Epoch [5/100], Loss: 6.8713\n",
      "Epoch [6/100], Loss: 6.8653\n",
      "Epoch [7/100], Loss: 6.8580\n",
      "Epoch [8/100], Loss: 6.8508\n",
      "Epoch [9/100], Loss: 6.8474\n",
      "Epoch [10/100], Loss: 6.8394\n",
      "Epoch [11/100], Loss: 6.8448\n",
      "Epoch [12/100], Loss: 6.8373\n",
      "Epoch [13/100], Loss: 6.8369\n",
      "Epoch [14/100], Loss: 6.8467\n",
      "Epoch [15/100], Loss: 6.8301\n",
      "Epoch [16/100], Loss: 6.8330\n",
      "Epoch [17/100], Loss: 6.8299\n",
      "Epoch [18/100], Loss: 6.8362\n",
      "Epoch [19/100], Loss: 6.8308\n",
      "Epoch [20/100], Loss: 6.8340\n",
      "Epoch [21/100], Loss: 6.8320\n",
      "Epoch [22/100], Loss: 6.8332\n",
      "Epoch [23/100], Loss: 6.8305\n",
      "Epoch [24/100], Loss: 6.8390\n",
      "Epoch [25/100], Loss: 6.8360\n",
      "Epoch [26/100], Loss: 6.8249\n",
      "Epoch [27/100], Loss: 6.8279\n",
      "Epoch [28/100], Loss: 6.8316\n",
      "Epoch [29/100], Loss: 6.8315\n",
      "Epoch [30/100], Loss: 6.8307\n",
      "Epoch [31/100], Loss: 6.8289\n",
      "Epoch [32/100], Loss: 6.8336\n",
      "Epoch [33/100], Loss: 6.8350\n",
      "Epoch [34/100], Loss: 6.8287\n",
      "Epoch [35/100], Loss: 6.8266\n",
      "Epoch [36/100], Loss: 6.8316\n",
      "Epoch [37/100], Loss: 6.8289\n",
      "Epoch [38/100], Loss: 6.8234\n",
      "Epoch [39/100], Loss: 6.8223\n",
      "Epoch [40/100], Loss: 6.8307\n",
      "Epoch [41/100], Loss: 6.8331\n",
      "Epoch [42/100], Loss: 6.8311\n",
      "Epoch [43/100], Loss: 6.8207\n",
      "Epoch [44/100], Loss: 6.8288\n",
      "Epoch [45/100], Loss: 6.8232\n",
      "Epoch [46/100], Loss: 6.8285\n",
      "Epoch [47/100], Loss: 6.8189\n",
      "Epoch [48/100], Loss: 6.8253\n",
      "Epoch [49/100], Loss: 6.8246\n",
      "Epoch [50/100], Loss: 6.8270\n",
      "Epoch [51/100], Loss: 6.8246\n",
      "Epoch [52/100], Loss: 6.8230\n",
      "Epoch [53/100], Loss: 6.8248\n",
      "Epoch [54/100], Loss: 6.8294\n",
      "Epoch [55/100], Loss: 6.8300\n",
      "Epoch [56/100], Loss: 6.8270\n",
      "Epoch [57/100], Loss: 6.8290\n",
      "Epoch [58/100], Loss: 6.8251\n",
      "Epoch [59/100], Loss: 6.8312\n",
      "Epoch [60/100], Loss: 6.8286\n",
      "Epoch [61/100], Loss: 6.8283\n",
      "Epoch [62/100], Loss: 6.8283\n",
      "Epoch [63/100], Loss: 6.8281\n",
      "Epoch [64/100], Loss: 6.8291\n",
      "Epoch [65/100], Loss: 6.8269\n",
      "Epoch [66/100], Loss: 6.8239\n",
      "Epoch [67/100], Loss: 6.8234\n",
      "Epoch [68/100], Loss: 6.8281\n",
      "Epoch [69/100], Loss: 6.8233\n",
      "Epoch [70/100], Loss: 6.8296\n",
      "Epoch [71/100], Loss: 6.8257\n",
      "Epoch [72/100], Loss: 6.8256\n",
      "Epoch [73/100], Loss: 6.8216\n",
      "Epoch [74/100], Loss: 6.8249\n",
      "Epoch [75/100], Loss: 6.8273\n",
      "Epoch [76/100], Loss: 6.8254\n",
      "Epoch [77/100], Loss: 6.8276\n",
      "Epoch [78/100], Loss: 6.8282\n",
      "Epoch [79/100], Loss: 6.8208\n",
      "Epoch [80/100], Loss: 6.8291\n",
      "Epoch [81/100], Loss: 6.8311\n",
      "Epoch [82/100], Loss: 6.8294\n",
      "Epoch [83/100], Loss: 6.8217\n",
      "Epoch [84/100], Loss: 6.8292\n",
      "Epoch [85/100], Loss: 6.8310\n",
      "Epoch [86/100], Loss: 6.8306\n",
      "Epoch [87/100], Loss: 6.8198\n",
      "Epoch [88/100], Loss: 6.8244\n",
      "Epoch [89/100], Loss: 6.8270\n",
      "Epoch [90/100], Loss: 6.8256\n",
      "Epoch [91/100], Loss: 6.8238\n",
      "Epoch [92/100], Loss: 6.8257\n",
      "Epoch [93/100], Loss: 6.8203\n",
      "Epoch [94/100], Loss: 6.8278\n",
      "Epoch [95/100], Loss: 6.8279\n",
      "Epoch [96/100], Loss: 6.8237\n",
      "Epoch [97/100], Loss: 6.8292\n",
      "Epoch [98/100], Loss: 6.8276\n",
      "Epoch [99/100], Loss: 6.8268\n",
      "Epoch [100/100], Loss: 6.8164\n",
      "Accuracy: 0.26%\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "train(model, train_loader, criterion, optimizer)\n",
    "evaluate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.6689e-01, -1.3814e+00,  1.0025e-01, -3.8229e-01, -7.9428e-02,\n",
       "         -1.3752e+00, -7.3961e-01, -7.5484e-01, -7.5546e-01, -3.8401e-01,\n",
       "         -3.6418e-01, -4.5579e-02, -3.6532e-01, -3.6226e-01, -7.3443e-01,\n",
       "         -1.3636e+00, -3.5683e-01, -3.6859e-01, -7.5375e-01, -3.6686e-01,\n",
       "         -3.5449e-01, -3.5599e-01, -3.8052e-01, -3.7812e-01, -3.5293e-01,\n",
       "         -7.5091e-01, -8.8756e-02, -7.5728e-01,  6.0805e-02, -1.3732e+00,\n",
       "         -3.1126e-01, -3.6534e-01, -7.5499e-01, -3.5745e-01, -3.7124e-01,\n",
       "         -3.6876e-01, -8.7290e-02, -7.3377e-01, -3.6198e-01, -3.5530e-01,\n",
       "         -4.0098e-01, -3.5933e-01, -7.8039e-02, -3.9074e-01, -3.5977e-01,\n",
       "         -3.5405e-01, -7.4658e-01, -8.4408e-02, -7.3806e-01, -7.5758e-01,\n",
       "         -3.5089e-01, -3.6132e-01, -3.5559e-01, -1.3478e+00, -1.0758e-01,\n",
       "         -6.8144e-01, -1.3580e+00, -7.7384e-01, -3.6308e-01, -3.6646e-01,\n",
       "         -8.4236e-02, -3.6630e-01, -3.7683e-01, -1.0148e-01, -3.6389e-01,\n",
       "         -7.4213e-01, -3.7279e-01, -6.0124e-01, -3.7105e-01, -3.6952e-01,\n",
       "         -7.4196e-01, -6.5048e+00,  1.0581e-01, -6.3646e+00, -3.5699e-01,\n",
       "         -2.8488e-01, -7.3020e-01, -7.5843e-01,  5.6591e-01, -3.6174e-01,\n",
       "         -3.5175e-01, -3.7879e-01, -7.3793e-01, -7.4782e-01, -2.9872e-01,\n",
       "         -3.7053e-01, -1.3630e+00, -3.6046e-01, -3.6354e-01, -9.9412e-02,\n",
       "         -7.4458e-01, -3.6698e-01, -3.7998e-01, -2.4814e-01, -3.7859e-01,\n",
       "         -3.7026e-01, -7.5811e-01, -6.7008e-01, -9.2027e-02, -1.3642e+00,\n",
       "         -9.3824e-02, -3.5781e-01, -7.5499e-01, -2.6009e-01, -2.6746e-01,\n",
       "         -3.6362e-01, -3.6236e-01,  2.2945e-01, -7.3705e-01, -7.4510e-01,\n",
       "         -1.3712e+00, -1.1273e-01, -2.2366e-01, -1.3677e+00, -9.7356e-02,\n",
       "         -7.4742e-01, -7.3046e-01, -3.6254e-01, -3.4958e-01, -7.6463e-01,\n",
       "         -1.1821e+00, -3.8041e-01, -1.3557e+00, -7.5628e-01, -7.3825e-01,\n",
       "         -7.5610e-01, -7.5529e-01, -7.1367e-01,  1.2384e-01, -3.9657e-01,\n",
       "         -3.6690e-01, -3.7020e-01, -3.7264e-01, -3.6606e-01, -2.4742e-01,\n",
       "         -3.6039e-01, -1.3588e+00, -3.8826e-01, -3.6047e-01, -1.3679e+00,\n",
       "         -3.5844e-01, -3.7265e-01, -1.0297e-01, -3.5538e-01, -3.5658e-01,\n",
       "         -3.9479e-01, -3.5200e-01, -3.8162e-01, -3.7709e-01, -3.6807e-01,\n",
       "         -7.5873e-01, -9.4818e-02, -9.0735e-02, -3.6181e-01, -9.1124e-02,\n",
       "         -9.7246e-02, -3.6837e-01, -3.3710e-01,  8.1829e-03, -3.5858e-01,\n",
       "         -3.7146e-01, -1.3663e+00, -7.9150e-02,  1.2116e-01, -7.6152e-01,\n",
       "         -3.6490e-01, -3.6219e-01,  2.9164e-01, -8.5809e-02, -7.3841e-01,\n",
       "         -7.8241e-02, -5.0904e-02, -2.5936e-01, -4.9444e-02, -3.7512e-01,\n",
       "         -7.3936e-01, -6.8865e-02, -7.4198e-01, -3.5964e-01, -1.3658e+00,\n",
       "         -3.7644e-01, -3.6819e-01, -3.6748e-01,  2.1438e-02, -3.8623e-01,\n",
       "         -3.6630e-01, -7.3781e-01, -7.3938e-01, -7.3566e-01, -7.3451e-01,\n",
       "         -7.4093e-01, -7.3815e-01, -1.3667e+00, -3.6593e-01,  5.2491e-01,\n",
       "         -3.1887e-01,  3.0981e-01, -3.5248e-01, -3.3738e-01, -7.3615e-01,\n",
       "         -7.3497e-01, -3.7859e-01, -1.3650e+00, -8.9948e-02, -1.0205e-01,\n",
       "         -3.5794e-01, -7.2327e-01, -8.7444e-02, -2.7928e-01, -3.7546e-01,\n",
       "         -7.5146e-01, -7.3730e-01, -9.0005e-02, -3.9316e-01, -3.7136e-01,\n",
       "         -5.8585e-01, -1.1346e-01, -8.0899e-02, -7.4843e-01, -1.0292e-01,\n",
       "         -3.9601e-01,  1.0756e-01, -9.1902e-02, -3.5296e-01, -3.8491e-01,\n",
       "         -3.7411e-01, -1.1055e-01, -1.1329e-01, -3.8467e-01,  2.1876e-01,\n",
       "         -3.0671e-01, -1.3544e+00, -7.2738e-01, -3.7689e-01, -7.4324e-01,\n",
       "         -3.5572e-01, -3.6770e-01, -3.6065e-01, -9.6450e-02, -3.5929e-01,\n",
       "         -7.7820e-01,  6.1490e-01, -9.6503e-02, -3.5612e-01, -7.5308e-01,\n",
       "         -8.7258e-02, -3.7966e-01, -3.1762e-02, -1.0721e-01, -7.3334e-01,\n",
       "          6.6756e-02, -1.3577e+00, -8.7847e-02, -3.5578e-01, -1.3097e+00,\n",
       "         -7.4249e-01, -3.6401e-01, -9.9423e-02, -2.7451e-01, -3.8209e-01,\n",
       "         -7.4169e-01, -3.1876e-01, -9.1091e-02, -9.1415e-02, -7.6733e-01,\n",
       "         -7.3387e-01, -7.3381e-01, -5.9268e-01, -3.6287e-01,  4.4007e-01,\n",
       "         -7.4869e-02, -3.8513e-01,  5.6387e-01, -7.0465e-01, -7.5496e-01,\n",
       "         -7.3507e-01,  1.9233e-01,  5.6301e-01, -7.6074e-01,  1.0515e-01,\n",
       "          1.0451e-01,  9.9056e-02,  1.1555e-01,  4.3002e-01, -7.2717e-01,\n",
       "         -3.6750e-01, -3.7684e-01, -3.1766e-01,  1.0140e-01, -3.5903e-01,\n",
       "         -1.1133e-01,  7.8915e-01,  4.4954e-01, -1.2943e+00, -8.3126e-02,\n",
       "         -6.7011e-02,  4.5278e-01,  2.8054e-01, -3.5523e-01, -3.7455e-01,\n",
       "         -3.6496e-01, -3.5614e-01, -3.6156e-01, -9.2470e-02, -2.8253e-01,\n",
       "         -3.7300e-01, -2.3537e-01, -3.7204e-01, -3.7074e-01, -7.4752e-01,\n",
       "          1.0666e-01, -3.7567e-01, -3.7202e-01, -3.5904e-01, -9.5923e-02,\n",
       "         -9.5852e-02,  1.0863e-01, -3.6003e-01, -3.6727e-01, -1.0256e-01,\n",
       "         -7.5668e-01, -3.6554e-01, -3.8151e-01, -7.9145e-02, -3.6377e-01,\n",
       "         -7.6849e-01, -6.7541e-01, -7.3509e-01, -6.7756e-01, -3.8370e-01,\n",
       "         -3.7271e-01,  1.2829e-01, -7.5466e-01, -3.6157e-01, -3.8326e-01,\n",
       "          2.9532e-01, -5.8638e-01, -7.4238e-01, -1.3819e+00, -3.6738e-01,\n",
       "         -1.3594e+00, -7.3673e-01, -7.4520e-01, -1.3659e+00, -1.3629e+00,\n",
       "         -3.0538e-01, -7.3334e-01, -3.6513e-01, -1.3535e+00, -7.3587e-01,\n",
       "         -7.3586e-01, -3.2933e-01, -3.6750e-01, -1.0090e-01, -3.7391e-01,\n",
       "         -3.5875e-01,  5.2557e-04, -3.5991e-01, -7.5696e-01, -8.2622e-02,\n",
       "          4.4896e-01, -3.8717e-01,  5.8410e-01, -6.0066e-01, -1.3523e+00,\n",
       "         -7.2379e-01, -7.2700e-01, -3.7108e-01, -3.8301e-01,  6.8531e-01,\n",
       "         -7.4799e-01,  5.6766e-01, -1.0497e-01, -1.3513e+00, -3.6632e-01,\n",
       "          1.1341e-01, -7.3768e-01, -7.4324e-01, -1.3531e+00, -7.4695e-01,\n",
       "         -3.6892e-01,  4.7162e-01, -3.5913e-01,  2.3733e-01, -1.3793e+00,\n",
       "          1.2886e-01, -8.7432e-02, -9.6022e-02, -3.6137e-01,  1.1695e-01,\n",
       "         -8.6239e-02, -1.0146e-01, -3.7313e-01, -7.5424e-01, -3.6053e-01,\n",
       "         -1.0131e-01, -7.5616e-01, -3.6511e-01, -9.3758e-02,  3.0219e-01,\n",
       "         -3.6955e-01, -7.5797e-01, -8.6675e-02, -6.8210e-03, -8.1028e-02,\n",
       "         -8.4411e-02, -1.3707e+00, -3.6593e-01,  2.7456e-01,  5.7226e-01,\n",
       "         -3.5525e-01, -3.5699e-01, -7.2952e-01, -3.5678e-01, -3.9590e-01,\n",
       "         -3.5895e-01,  1.2936e-01, -1.1909e-01, -3.6418e-01,  1.6811e-01,\n",
       "         -9.5548e-02, -3.5997e-01,  1.2802e-01, -3.6897e-01, -3.2916e-01,\n",
       "         -3.6595e-01, -3.7300e-01, -7.3815e-01, -6.2966e+00, -3.6487e-01,\n",
       "         -3.6062e-01, -8.7057e-02, -3.5391e-01, -1.3547e+00, -7.5135e-01,\n",
       "         -3.7715e-01, -3.6329e-01, -1.0658e-01, -3.7040e-01, -1.0099e-01,\n",
       "         -7.5120e-01, -8.6489e-02, -1.3462e+00, -9.2747e-02, -3.5751e-01,\n",
       "         -6.2331e-01,  4.3888e-01, -9.2509e-02, -7.4642e-01, -3.6013e-01,\n",
       "          2.9941e-01, -3.4664e-01, -3.5566e-01, -8.8831e-02, -3.8697e-01,\n",
       "         -4.2083e-02, -3.6407e-01, -3.7426e-01, -9.8082e-02, -8.7545e-02,\n",
       "         -3.6771e-01, -7.4720e-01, -8.8861e-02,  1.2040e-01, -7.5198e-02,\n",
       "         -8.6066e-02, -3.6948e-01, -1.0674e-01, -3.5793e-01, -3.5805e-01,\n",
       "         -9.3697e-02, -2.9779e-01, -3.7575e-01,  7.1380e-01, -8.4358e-02,\n",
       "         -9.5487e-02, -2.5851e-01, -8.9693e-02, -1.3774e+00, -7.2538e-01,\n",
       "         -1.0973e-01, -3.6211e-01,  1.1200e-01, -3.6094e-01, -1.0567e-01,\n",
       "         -7.3501e-01, -3.7551e-01,  3.0140e-01, -5.6510e-02, -3.8313e-01,\n",
       "         -3.5924e-01, -3.6260e-01, -3.6313e-01, -8.5837e-02, -1.1296e-01,\n",
       "         -3.5797e-01, -7.5517e-01, -3.7243e-01, -7.4061e-01, -3.5586e-01,\n",
       "         -2.1185e-01, -3.7033e-01,  1.2698e-01, -1.2736e+00, -3.7502e-01,\n",
       "         -3.5591e-01, -1.3620e+00, -7.3147e-01, -1.1803e-01, -7.3598e-01,\n",
       "          5.6124e-01, -3.5718e-01,  7.9328e-01, -3.6609e-01, -9.7413e-02,\n",
       "         -7.4215e-01, -3.6444e-01, -9.2419e-02, -3.2359e-01, -1.0571e-01,\n",
       "         -7.3886e-01, -7.3577e-01, -3.6404e-01, -7.2866e-02, -8.7508e-02,\n",
       "         -3.7526e-01, -9.9453e-02, -3.6181e-01, -3.7467e-01, -3.7045e-01,\n",
       "          1.1274e-01, -3.6816e-01, -3.7300e-01, -7.4933e-01, -1.1292e-01,\n",
       "         -1.7779e-01, -9.6047e-02, -7.3629e-01, -1.3739e+00, -1.3681e+00,\n",
       "         -8.7759e-02, -3.5993e-01, -6.4730e+00, -3.7037e-01, -3.6640e-01,\n",
       "         -2.2329e-01, -3.6931e-01, -1.0311e-01,  4.4929e-01, -7.3537e-01,\n",
       "          7.7592e-01,  4.6078e-01, -7.4861e-01, -3.6026e-01, -7.5618e-01,\n",
       "         -7.4606e-01,  1.3181e-01, -8.9828e-02, -7.4929e-01, -3.6992e-01,\n",
       "         -6.1108e-01, -3.6680e-01,  2.4986e-02, -7.5354e-01, -1.3680e+00,\n",
       "         -3.7284e-01, -3.6368e-01, -3.5097e-01, -6.8807e-01, -9.7399e-02,\n",
       "         -1.1146e-01, -3.7421e-01, -9.5734e-02, -3.7925e-01, -3.7254e-01,\n",
       "         -7.3552e-01, -3.9217e-01,  2.9141e-01, -3.7427e-01, -7.6172e-01,\n",
       "         -1.3526e+00, -3.8069e-01, -2.5197e-01, -9.0848e-02, -1.3836e+00,\n",
       "         -1.0696e-01, -1.2661e+00, -7.7210e-01, -1.0074e-01, -3.8623e-01,\n",
       "         -3.5451e-01, -7.3280e-01, -7.3698e-01, -3.7887e-01, -1.3490e+00,\n",
       "          2.4002e-01, -9.4175e-02, -2.6963e-01, -9.2565e-02, -9.2840e-02,\n",
       "         -1.3490e+00, -8.7124e-02, -7.3181e-01, -3.8817e-01,  2.0956e-01,\n",
       "          2.8839e-01,  5.6342e-01, -3.9070e-01, -1.3642e+00, -9.1633e-02,\n",
       "         -7.4137e-01, -3.6392e-01, -3.7277e-01, -7.0589e-02, -3.6977e-01,\n",
       "          4.3957e-01, -3.6241e-01,  4.4097e-01, -3.5083e-01, -3.7742e-01,\n",
       "          2.8665e-01, -3.6634e-01, -1.3639e+00, -9.6592e-02, -7.3889e-01,\n",
       "         -3.5705e-01,  1.1770e-01, -3.6629e-01, -9.8634e-02, -7.4143e-01,\n",
       "         -3.5886e-01, -1.1343e-01,  1.4825e-01, -2.2327e-01, -2.0124e-01,\n",
       "         -1.3601e+00,  1.1633e-01, -3.8177e-01, -3.6837e-01, -7.4047e-01,\n",
       "         -7.5238e-01,  1.1359e-01, -3.7971e-01, -7.2934e-01, -7.4410e-01,\n",
       "         -3.6630e-01, -7.2460e-01, -1.3573e+00, -3.8081e-01, -7.4227e-01,\n",
       "         -3.8028e-01, -1.0550e-01, -6.1558e-02, -7.9334e-02, -7.3222e-01,\n",
       "         -3.7200e-01, -3.7913e-01, -8.8182e-02, -5.8362e-01, -1.3511e+00,\n",
       "         -8.2683e-02, -7.0096e-01, -7.6669e-01, -3.7576e-01, -7.3659e-01,\n",
       "         -7.5251e-01, -7.2978e-01,  1.2762e-01, -3.5712e-01,  1.0515e-01,\n",
       "         -7.4704e-01, -2.0173e-01, -3.3686e-01,  1.1035e-01, -9.5571e-02,\n",
       "         -3.5310e-01, -7.4842e-01, -3.7357e-01, -7.5982e-01, -7.4659e-01,\n",
       "          2.8668e-01, -7.4106e-01, -1.0073e-01,  2.8485e-01, -3.5945e-01,\n",
       "          9.2037e-02, -3.7583e-01, -3.5355e-01,  1.5446e-01, -1.3895e+00,\n",
       "         -3.6028e-01, -9.8729e-02, -3.6617e-01, -7.4751e-01, -7.3719e-01,\n",
       "         -1.3522e+00, -9.4646e-02, -7.3461e-01, -7.7711e-01, -9.6004e-02,\n",
       "          5.7884e-01, -1.0608e-01,  2.7632e-01, -1.3749e+00, -3.6629e-01,\n",
       "         -7.4937e-01, -7.3249e-01, -7.3132e-01, -3.6680e-01, -8.6643e-02,\n",
       "         -2.6749e-01, -7.9050e-02, -9.3521e-02,  2.9733e-01, -6.4604e-01,\n",
       "         -1.0781e-01, -3.8339e-01, -2.4066e-01, -8.7435e-02, -7.3734e-01,\n",
       "         -3.8084e-01, -7.0136e-01, -3.8292e-01, -7.3182e-01, -7.5053e-01,\n",
       "         -3.5362e-01,  1.3227e-01, -7.3086e-01, -1.3781e+00, -3.6614e-01,\n",
       "         -3.6488e-01, -3.7892e-01, -2.9928e-01, -9.9011e-02, -1.3593e+00,\n",
       "         -3.7087e-01, -9.1828e-02, -3.6167e-01, -7.5935e-01, -3.6567e-01,\n",
       "         -3.5220e-01, -7.5760e-01, -3.6952e-01, -9.3126e-02, -8.3260e-02,\n",
       "         -8.1427e-02, -2.9217e-01, -1.0340e-01, -1.1735e-01,  1.1414e-01,\n",
       "          1.2034e-01, -7.5016e-01, -6.0223e-01, -3.5413e-01, -7.1283e-01,\n",
       "         -1.0932e-01, -3.5572e-01, -2.9120e-01, -7.5351e-01, -3.3026e-01,\n",
       "         -1.3708e+00, -3.6473e-01, -3.6194e-01,  4.5370e-01, -2.0130e-01,\n",
       "          1.2405e-01, -3.5404e-01, -3.5884e-01, -3.7071e-01, -8.5684e-02,\n",
       "         -1.0920e-01,  1.2754e-01, -3.6815e-01, -3.4803e-01, -3.3378e-01,\n",
       "         -3.5585e-01, -3.6326e-01,  1.2033e-01,  1.2218e-01, -7.5455e-01,\n",
       "          2.9350e-01, -3.5324e-01,  1.2970e-01, -1.0611e-01, -3.5491e-01,\n",
       "         -9.6689e-02, -9.8334e-02, -3.7701e-01, -7.3565e-01, -1.0823e-01,\n",
       "         -3.5276e-01, -7.3604e-01, -3.6009e-01, -3.7963e-01, -8.3515e-02,\n",
       "         -3.7324e-01, -1.3558e+00, -3.6055e-01, -1.0519e-01, -7.4300e-01,\n",
       "         -3.5363e-01, -3.6917e-01, -9.2798e-02, -1.1136e-01, -3.7751e-01,\n",
       "          2.8374e-01, -7.2530e-01, -1.3965e+00, -3.2988e-01, -7.3714e-01,\n",
       "         -3.8027e-01, -7.3806e-01, -9.8978e-02,  1.2354e-01, -8.9157e-02,\n",
       "         -3.7324e-01, -3.5661e-01, -1.2642e+00, -3.6771e-01, -3.0198e-01,\n",
       "         -7.2392e-01, -1.0069e-01, -3.2467e-01, -3.5047e-01, -3.8787e-01,\n",
       "         -3.6006e-01, -8.9132e-02, -1.3615e+00, -3.7586e-01, -3.6510e-01,\n",
       "         -7.2584e-01, -3.4589e-02, -7.4595e-01, -2.0137e-02, -7.4518e-01,\n",
       "         -4.0042e-01, -9.9049e-02, -8.7594e-02, -9.5460e-02, -7.5823e-01,\n",
       "          2.8561e-01, -3.5750e-01, -3.4123e-01, -3.6917e-01,  1.0743e-01,\n",
       "         -3.6985e-01, -1.0610e-01, -3.8296e-01,  5.7208e-02, -7.5912e-01,\n",
       "         -7.2429e-01, -3.4783e-01, -8.9539e-02, -3.6176e-01, -1.3626e+00,\n",
       "         -3.6262e-01, -1.0063e-01, -3.6687e-01, -3.2945e-01,  2.9339e-01,\n",
       "         -7.2806e-01, -7.3911e-01, -7.5139e-01, -7.0986e-01, -6.4704e-01,\n",
       "         -7.5657e-01, -1.3647e+00, -7.5161e-01, -2.2417e-01, -3.5762e-01,\n",
       "         -7.4929e-01, -3.6570e-01, -7.2016e-01, -3.5411e-01, -1.3659e+00,\n",
       "         -1.3578e+00, -9.8564e-02, -3.5811e-01, -3.6060e-01, -7.4399e-01,\n",
       "         -1.1796e+00, -7.4447e-01, -3.6846e-01, -7.3263e-01, -3.6536e-01,\n",
       "         -1.3955e+00,  6.4825e-02, -3.6937e-01, -2.5952e-01, -7.4224e-01,\n",
       "         -8.0128e-02, -3.5924e-01, -7.2877e-01, -1.0261e-01,  1.1906e-01,\n",
       "         -3.2044e-02,  1.8615e-01, -7.3869e-01, -3.6525e-01, -1.1063e-01,\n",
       "         -1.1294e-01, -1.3741e+00,  8.9456e-01,  1.0364e-01, -1.3658e+00,\n",
       "         -3.8066e-01, -2.5150e-01, -3.6955e-01, -3.6346e-01, -3.8382e-01,\n",
       "         -3.8544e-02, -1.3656e+00, -3.5994e-01, -9.7582e-02, -8.5358e-02,\n",
       "         -1.0337e-02, -3.6507e-01, -3.4906e-01, -3.6674e-01, -3.6903e-01,\n",
       "         -3.6430e-01, -7.5150e-01, -7.9211e-02, -2.1849e-01, -7.4479e-01,\n",
       "         -3.6031e-01, -7.4705e-01, -1.9702e-01, -8.0444e-02, -5.7523e-02,\n",
       "         -1.3458e+00, -3.7815e-01, -1.3683e+00, -3.6667e-01, -3.6145e-01,\n",
       "         -6.5299e+00, -7.2877e-01, -3.8759e-01, -3.6097e-01, -1.3584e+00,\n",
       "         -7.6666e-02, -3.6170e-01, -8.4181e-02, -5.3582e-02, -6.3399e-02,\n",
       "         -5.5569e-02, -7.2624e-01, -7.3607e-01,  1.2817e-01,  2.3380e-01,\n",
       "         -9.2188e-02, -7.4561e-01, -8.2793e-02, -3.7315e-01, -3.6757e-01,\n",
       "         -7.4622e-01, -9.8384e-02, -9.1740e-02, -3.8436e-01, -7.6628e-01,\n",
       "         -5.7064e-01, -3.7268e-01, -3.7059e-01, -1.3570e+00, -3.6790e-01,\n",
       "         -9.4285e-02, -3.6542e-01, -9.5454e-02, -8.4451e-02,  1.0781e-01,\n",
       "         -3.5443e-01, -2.7739e-01, -6.8781e-02, -1.3549e+00, -7.4580e-01,\n",
       "         -3.6089e-01, -9.5372e-02, -3.5701e-01, -1.0412e-01, -3.5422e-01,\n",
       "         -7.2876e-01, -6.7876e-01, -9.0687e-02, -3.6288e-01, -8.4841e-02,\n",
       "         -2.0650e-01, -3.6501e-01, -3.6420e-01, -3.6505e-01, -7.8783e-01,\n",
       "         -3.6833e-01, -7.4365e-01, -1.3855e+00, -2.6915e-01, -8.1308e-02,\n",
       "         -7.4628e-01, -2.7738e-01, -1.0513e-01, -7.3831e-01,  1.8088e-01]],\n",
       "       device='mps:0', grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model(train_set[0][0].unsqueeze(0).to(device))\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majority_class_pred = torch.argmax(prediction)\n",
    "majority_class_pred.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "910"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][1].item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compvis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
